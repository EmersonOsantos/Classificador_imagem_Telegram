# -*- coding: utf-8 -*-
"""Trabalho1-IA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t2XaakmI82weuU3Rnl_l1ofXkfhm9n8T
"""

from google.colab import drive
drive.mount('/content/drive')

import os
from pathlib import Path
from sklearn.model_selection import train_test_split
import shutil

#Diretório base dos dados
dir_base = Path('/content/drive/My Drive/FotosIA')

#Nome das classes dentro do dataset
classes = ['Céu', 'Comida']

#Cria diretórios para treino, validação e teste dentro da pasta FotosIA
for i in ['train', 'val', 'test']:
    for cls in classes:
        os.makedirs(dir_base / i / cls, exist_ok=True)

#Função para dividir os dados
def divide_dados(dir_src, dir_dest, split_ratio):
    #Lista todas as imagens no diretório de origem
    arquivos = [f for f in os.listdir(dir_src) if f.lower().endswith(('jpg', 'jpeg', 'png', 'ppm', 'bmp', 'pgm', 'tif', 'tiff', 'webp'))]
    #Divide os arquivos em conjuntos de treino e validação/teste
    arquivos_treino, arquivos_val_teste = train_test_split(arquivos, test_size = split_ratio[1] + split_ratio[2])
    #Divide o conjunto de validação/teste em conjuntos de validação e teste
    val_files, test_files = train_test_split(arquivos_val_teste, test_size = split_ratio[2] / (split_ratio[1] + split_ratio[2]))

    #Copia os conjuntos de arquivos para seus respectivos diretórios
    for file in arquivos_treino:
        shutil.copy(dir_src / file, dir_dest / 'train' / dir_src.name / file)
    for file in val_files:
        shutil.copy(dir_src / file, dir_dest / 'val' / dir_src.name / file)
    for file in test_files:
        shutil.copy(dir_src / file, dir_dest / 'test' / dir_src.name / file)

#Divide os dados (70% para treino, 15% para validação e 15% para teste)
split_ratio = [0.7, 0.15, 0.15]
for cls in classes:
    divide_dados(dir_base / cls, dir_base, split_ratio)

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, models, transforms

#Transformações/Nomralizações de dados

data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}

#Diretório inicial dos dados
data_dir = '/content/drive/My Drive/FotosIA'
#Cria o datasets de imagens e aplica as transformações nas imagens
imagem_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val', 'test']}
#Cria dataloaders para carregar os dados em mini-batchs durante o treinamento
dataloaders = {x: torch.utils.data.DataLoader(imagem_datasets[x], batch_size=32, shuffle=True, num_workers=2) for x in ['train', 'val', 'test']}
#Calcula os tamanhos dos datasets
dataset_sizes = {x: len(imagem_datasets[x]) for x in ['train', 'val', 'test']}
#Obtém os nomes das classes
class_names = imagem_datasets['train'].classes

#Usará a GPU se disponível, caso contrário, usará a CPU para as execuções
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

#Função para treinar os modelos

def train_model(model, criterion, optimizer, num_epochs=25):
    for epoch in range(num_epochs):
        print(f'Epoch {epoch}/{num_epochs - 1}')
        print('-' * 10)

        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()
            else:
                model.eval()

            running_loss = 0.0
            running_corrects = 0

            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                optimizer.zero_grad()

                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]

            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

        print()

    return model

#Carrega o modelo pré-treinado AlexNet e modifica a última camada (Finetuning)

alexnet = models.alexnet(pretrained=True)
num_ftrs = alexnet.classifier[6].in_features
alexnet.classifier[6] = nn.Linear(num_ftrs, len(class_names))
alexnet = alexnet.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(alexnet.parameters(), lr=0.001, momentum=0.9)

alexnet

#Treina o modelo AlexNet
alexnet = train_model(alexnet, criterion, optimizer, num_epochs=5)

#Salva o modelo AlexNet no google drive
alexnet_dir = '/content/drive/My Drive/FotosIA/AlexNet.pth'
torch.save(alexnet.state_dict(), alexnet_dir)

#Carrega o modelo pré-treinado Densenet169 e modifica a última camada (Finetuning)

densenet = models.densenet169(pretrained=True)
num_ftrs = densenet.classifier.in_features
densenet.fc = nn.Linear(num_ftrs, len(class_names))
densenet = densenet.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(densenet.parameters(), lr=0.001, momentum=0.9)

densenet

#Treina o modelo densenet
densenet = train_model(densenet, criterion, optimizer, num_epochs=5)

#Salva o modelo Densenet169 no google drive
densenet_dir = '/content/drive/My Drive/FotosIA/DenseNet.pth'
torch.save(densenet.state_dict(),densenet_dir)

from sklearn.metrics import classification_report

#Função para avaliar um modelo treinado no conjunto de dados de teste
def avaliar_modelo(modelo):
    # Set the model to evaluation mode. This disables dropout layers and uses running statistics for batch normalization.
    modelo.eval()

    # Initialize lists to store true labels and predicted labels
    all_labels = []
    all_preds = []

    # Disable gradient calculation to save memory and computations
    with torch.no_grad():
        # Loop over the test dataset
        for inputs, labels in dataloaders['test']:
            # Move inputs and labels to the device (CPU or GPU)
            inputs = inputs.to(device)
            labels = labels.to(device)

            # Get model outputs for the inputs
            outputs = modelo(inputs)
            # Get the predicted class by finding the index of the maximum value in the outputs
            _, preds = torch.max(outputs, 1)

            # Convert the labels and predictions to numpy arrays and add them to the lists
            all_labels.extend(labels.cpu().numpy())
            all_preds.extend(preds.cpu().numpy())

    # Return the true labels and predicted labels
    return all_labels, all_preds

#Avalia o AlexNet
y_true, y_pred = avaliar_modelo(alexnet)
print("AlexNet Classification Report:")
print(classification_report(y_true, y_pred, target_names=class_names))

#Avalia o Densenet169
y_true, y_pred = avaliar_modelo(densenet)
print("Densenet169 Classification Report:")
print(classification_report(y_true, y_pred, target_names=class_names))

"""#Classificaçao de imagem"""

from PIL import Image
import matplotlib.pyplot as plt

#Função para carregar e pré-processar a imagem
def process_image(image_path):
    image = Image.open(image_path)
    transform = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    image = transform(image).unsqueeze(0)
    return image

#Função para classificar a imagem usando um dos modelos
def classify_image(model, image_path):
    model.eval()
    image = process_image(image_path)
    image = image.to(device)

    with torch.no_grad():
        outputs = model(image)
        _, preds = torch.max(outputs, 1)
        class_idx = preds.item()
        class_name = class_names[class_idx]

    return class_name

#Caminho da imagem a ser classificada
image_path = '/content/drive/My Drive/FotosIA/testes/teste1.jpeg'

#Classifica a imagem usando AlexNet
class_name_alexnet = classify_image(alexnet, image_path)
print(f'Classificação usando AlexNet: {class_name_alexnet}')

#Classifica a imagem usando GoogLeNet
class_name_desenet = classify_image(densenet, image_path)
print(f'Classificação usando GoogLeNet: {class_name_desenet}')

#Exibe a imagem e as classificações dadas pelos dois modelos
image = Image.open(image_path)
plt.imshow(image)
plt.title(f'Classificação: {class_name_alexnet} (AlexNet), {class_name_desenet} (Densenet169)')
plt.axis('off')
plt.show()

"""TELEGRAM"""

!pip install torch torchvision python-telegram-bot nest_asyncio

import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import io
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
import nest_asyncio
import asyncio

#Permitir reentrância no loop de eventos
nest_asyncio.apply()

#Função para carregar o modelo AlexNet
def carrega_modelo(caminho_do_modelo):
    modelo = models.alexnet(pretrained=True)
    num_ftrs = modelo.classifier[6].in_features
    modelo.classifier[6] = nn.Linear(num_ftrs, 2)
    modelo.load_state_dict(torch.load(caminho_do_modelo, map_location=torch.device('cpu')))
    modelo.eval()
    return modelo

#Caminho para o modelo treinado
caminho_do_modelo = '/content/drive/My Drive/FotosIA/AlexNet.pth'
modelo = carrega_modelo(caminho_do_modelo)

#Transformações de imagem
transforma = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

class_names = ['Céu', 'Comida']

#Função para classificar a imagem
def classifica_imagem(imagem):
    imagem = transforma(imagem).unsqueeze(0)
    with torch.no_grad():
        outputs = modelo(imagem)
        _, preds = torch.max(outputs, 1)
        class_idx = preds.item()
        class_name = class_names[class_idx]
    return class_name

#Função para responder ao comando /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.message.reply_text('Olá! Envie-me uma foto do Céu ou uma comida para que eu possa classificá-la.')

#Função para responder a fotos enviadas
async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    photo_file = await update.message.photo[-1].get_file()
    photo_bytes = await photo_file.download_as_bytearray()
    imagem = Image.open(io.BytesIO(photo_bytes))
    class_name = classifica_imagem(imagem)
    await update.message.reply_text(f'Eu acho que isso é um(a) {class_name}')

#Função para configurar o bot
async def main():
    application = ApplicationBuilder().token("7239221335:AAFP7bbLzO8NXco1lqKi8CdQyzYoF3wsS4k").build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.PHOTO, handle_photo))

    await application.run_polling()

#Executa o bot
await main()